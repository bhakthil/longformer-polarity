{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "5a86d436",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import datasets\n",
    "from datasets import Dataset\n",
    "from datasets import load_dataset\n",
    "from transformers import LongformerTokenizerFast, LongformerForSequenceClassification, Trainer, TrainingArguments, LongformerConfig\n",
    "import torch.nn as nn\n",
    "import torch\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import numpy as np\n",
    "from sklearn.metrics import accuracy_score, precision_recall_fscore_support\n",
    "from tqdm import tqdm\n",
    "#import wandb\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "cc7a4086",
   "metadata": {},
   "outputs": [],
   "source": [
    "#train_df = pd.read_csv('./v1/articles_train.tsv', index_col=False, sep='\\t')\n",
    "#validate_df = pd.read_csv('./v1/articles_validate.tsv', index_col=False, sep='\\t')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "564e4355",
   "metadata": {},
   "outputs": [],
   "source": [
    "### convert pandas df (only columns 'titletext' and 'label') to nlp Dataset\n",
    "#train_data = Dataset.from_pandas(train_df[['context','label']])\n",
    "#validation_data = Dataset.from_pandas(validate_df[['context','label']])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13736ec9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "13a2d85f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using custom data configuration default-1c361d7acb47da84\n",
      "Reusing dataset csv (/home/bhakthi/.cache/huggingface/datasets/csv/default-1c361d7acb47da84/0.0.0/9144e0a4e8435090117cea53e6c7537173ef2304525df4a077c435d8ee7828ff)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9b64891da627479aaaf997e3263e31d9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/3 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "_features=datasets.Features(\n",
    "    {\n",
    "        \"content\": datasets.Value(\"string\"),\n",
    "        \"label\": datasets.Value(\"int64\"),\n",
    "        \"polarity\": datasets.ClassLabel(num_classes=5, names=['Left','LeanLeft','Center','LeanRight','Right'])\n",
    "        \n",
    "    }\n",
    ")\n",
    "\n",
    "dataset = load_dataset('csv', data_files={\n",
    "    \"train\": './v1/articles_train.tsv',\n",
    "    \"validation\": './v1/articles_validate.tsv',\n",
    "    \"test\": './v1/articles_test.tsv',\n",
    "}, delimiter=\"\\t\")\n",
    "\n",
    "# ['train', 'test']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "8bdb4f25",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Right'"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset['train'][10]['polarity']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "3e498e9d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading cached processed dataset at /home/bhakthi/.cache/huggingface/datasets/csv/default-1c361d7acb47da84/0.0.0/9144e0a4e8435090117cea53e6c7537173ef2304525df4a077c435d8ee7828ff/cache-d1cfad0eb3e59adc.arrow\n",
      "Loading cached processed dataset at /home/bhakthi/.cache/huggingface/datasets/csv/default-1c361d7acb47da84/0.0.0/9144e0a4e8435090117cea53e6c7537173ef2304525df4a077c435d8ee7828ff/cache-058cc024f1c38e2e.arrow\n",
      "Loading cached processed dataset at /home/bhakthi/.cache/huggingface/datasets/csv/default-1c361d7acb47da84/0.0.0/9144e0a4e8435090117cea53e6c7537173ef2304525df4a077c435d8ee7828ff/cache-b2b69b1c7176c7da.arrow\n"
     ]
    }
   ],
   "source": [
    "### https://github-dotcom.gateway.web.tr/huggingface/datasets/issues/2365\n",
    "dataset = dataset.map(_features.encode_example, features=_features)\n",
    "#dataset['train'].cast_(_features)\n",
    "#print(dataset.keys())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "109fb232",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset['train'][10]['polarity']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "f9d90627",
   "metadata": {},
   "outputs": [],
   "source": [
    "#dataset.cast_(_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "c4c85312",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DatasetDict({\n",
       "    train: Dataset({\n",
       "        features: ['content', 'label', 'polarity'],\n",
       "        num_rows: 310553\n",
       "    })\n",
       "    validation: Dataset({\n",
       "        features: ['content', 'label', 'polarity'],\n",
       "        num_rows: 69875\n",
       "    })\n",
       "    test: Dataset({\n",
       "        features: ['content', 'label', 'polarity'],\n",
       "        num_rows: 7764\n",
       "    })\n",
       "})"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "5e914351",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data = dataset['train']\n",
    "validation_data = dataset['validation']\n",
    "test_data = dataset['test']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "24920470",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data[10]['polarity']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "52d5d0de",
   "metadata": {},
   "outputs": [],
   "source": [
    "# load model and tokenizer and define length of the text sequence\n",
    "#model = LongformerForSequenceClassification.from_pretrained('allenai/longformer-base-4096',\n",
    "#                                                           gradient_checkpointing=False,\n",
    "#                                                          attention_window = 512)\n",
    "tokenizer = LongformerTokenizerFast.from_pretrained('allenai/longformer-base-4096', max_length = 2048)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "7012ac30",
   "metadata": {},
   "outputs": [],
   "source": [
    "label_map = {'Right':0,'LeanRight':1,'Center':2,'LeanLeft':3,'Left':4}\n",
    "def convert_to_features(example):\n",
    "    # Tokenize contexts and questions (as pairs of inputs)\n",
    "    encodings = tokenizer.encode_plus(example['content'], pad_to_max_length=True, max_length=2048,\n",
    "                                           add_special_tokens=True,\n",
    "                                            return_token_type_ids=False,\n",
    "                                            return_attention_mask=True,\n",
    "                                            padding='max_length', truncation=True,\n",
    "                                           )\n",
    "    \n",
    "    #label = torch.tensor(polarity,dtype=torch.int64)\n",
    "    #encodings.update({'label': label,\n",
    "    #                  'attention_mask': encodings['attention_mask']})\n",
    "    return encodings"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b64b0afc",
   "metadata": {},
   "source": [
    "### We will sample this data for testing purpose only"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "01e7518c",
   "metadata": {},
   "source": [
    "## Take subset of data\n",
    "train_size = 20000\n",
    "val_size = 5000\n",
    "import numpy as np\n",
    "train_indices = np.random.randint(0, len(dataset['train']), train_size)\n",
    "val_indices = np.random.randint(0, len(dataset['validation']), val_size)\n",
    "train_data = dataset['train'].select(train_indices)\n",
    "validation_dataset = dataset['validation'].select(val_indices)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "5d73295c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "80eb15ace5744c61926af636f5f9ff61",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/310553 [00:00<?, ?ex/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c8c1703aff2547e1b17147c734799364",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/69875 [00:00<?, ?ex/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "train_data =  train_data.map(convert_to_features, load_from_cache_file=False)\n",
    "validation_data =  validation_data.map(convert_to_features, load_from_cache_file=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "355b7cc7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "53f507c5d6cf4f2caa743084a8035df0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/7764 [00:00<?, ?ex/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "test_data =  test_data.map(convert_to_features, load_from_cache_file=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c208e15",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "3d16faf3",
   "metadata": {},
   "outputs": [],
   "source": [
    "columns = ['input_ids', 'attention_mask', 'label']\n",
    "train_data.set_format(type='torch', columns=columns)\n",
    "validation_data.set_format(type='torch', columns=columns)\n",
    "test_data.set_format(type='torch', columns=columns)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "08d44d28",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(train_data, './v1/train_data.pt')\n",
    "torch.save(validation_data, './v1/validation_data.pt')\n",
    "torch.save(test_data, './v1/test_data.pt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "f819d22f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'label': tensor(4),\n",
       " 'input_ids': tensor([   0, 6460,   70,  ...,    1,    1,    1]),\n",
       " 'attention_mask': tensor([1, 1, 1,  ..., 0, 0, 0])}"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data[10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "5d39e428",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'<s>get all the latest news on coronavirus and more delivered daily to your inbox sign up here we brought you fresh reporting thursday night about the origins of the deadly coronavirus pandemic now we have more we spent much of the day speaking to highly informed officials in the yous government as well as seasoned specialists on china first many in the intelligence world with experience in china suspected right away that the story the chinese government was telling about this virus was almost certainly a lie the first indication of that from official sources in beijing bret baier says more and more dots point to wuhan lab as origin of coronavirus pandemic initially chinese officials claimed the virus had jumped from an obscure scaly animal called a pangolin which was sold in the wuhan wet market that explanation didn t make sense wet markets are seafood markets pangolins are mammals so are bats which were also suspected as the source of the coronavirus in the face of skepticism the chinese then d been near wuhan a few months before for the military world games an international sporting event the italians brought the virus the chinese said when the italian government complained the chinese shifted blame to the united states the american military and western tourists infected wuhan they claimed meanwhile behind the scenes chinese officials worked frantically to destroy relevant evidence doctors and journalists in wuhan who raised questions about the virus disappeared some may have been killed at one succeeded in sequencing dna from the virus the information they gathered would have been crucial to researchers around the world who were trying to understand the virus and develop vaccines against it but the chinese government ordered the viral samples destroyed and the lab notes shredded the scientists themselves were disciplined for daring to conduct the research and their lab was shut down us officials confirm fullscale investigation of whether coronavirus escaped from wuhan lab the chinese government then quarantined the city of wuhan millions fled were allowed to travel to beijing the chinese capital instead they flew to cities around the world to most in this country reactions like this seem grotesque unimaginable but to mandarin speakers who follow china carefully they were highly familiar the first reflex of the chinese government is always to lie in order to hide failure and avoid embarrassment in the chinese government lied about the initial outbreak of sars in july two passenger trains traveling in high speed outside the chinese city of wenjo the trains collided on a railroad bridge four cars derailed and tumbled to the ground below within hours authorities arrived with backhoes they pushed the passenger cars into a pit and began covering them with dirt by some accounts there were still survivors inside at the time in their initial statements chinese officials claimed that a lightning strike had caused the crash they later conceded under pressure that sloppiness and shoddy construction were to blame ordered ignore the crash entirely except for positive news or that issued by the authorities this was the template for china s official response to the wuhan coronavirus from the early days of the outbreak chinese diplomats around the world insisted that there was no chance whatsoever that the virus had come from a lab they sometimes insisted this even when no one had asked them as if they were reading from a script it soon became obvious what was going on englishlanguage about the safety standards in the wuhan bioresearch lab an article in nature from noted that some scientists outside china worry about pathogens escaping from the facility classified state department cables a year later voiced the same concerns chinese scientists themselves publicly discussed working with extremely dangerous pathogens in wuhan as of today says someone in a position to know there is almost unanimous agreement in american intelligencegathering agencies that the virus currently destroying much of the world originally emerged from a this country have believed that for some time they ve been unable to interest our media in writing about it in recent weeks analysts from the cia national security agency and others have briefed staff at the new york times about the origins of this virus the newspaper has still not reported their findings at the same time and this may be directly related china has been waging an unremitting propaganda war on the subject chinese officials have tried to squelch all conversations pandemic by inflaming the political sensitivities and race guilt of american elites in one case the spokesman for the chinese foreign ministry attempted to dictate how american press outlets describe the virus zhao lijian spokesman for the chinese foreign ministry said certain media say this coronavirus is a china virus this is extremely irresponsible and we firmly oppose that among the many ironies in that demand even now the disease is widely referred to in china as the wuhan virus almost always call it covid that term does not translate to chinese covid is the name devised by the world health organization back in january under influence from chinese leaders anxious to deflect responsibility for it once they succeeded in removing any hint of origin from the name of the virus the chinese government launched a campaign to tar anyone who mentioned wuhan as a dangerous racist racism is not the right tool to cover your own incompetence lectured chinese state media when president american media parroted that line almost precisely as no doubt the chinese expected they would cnn white house correspondent jim acosta said the president referred to the coronavirus as a foreign virus and i think it s going to smack it s going to come across to a lot of americans as smacking of xenophobia on msnbc contributor john heilemann said xenophobic wartime trump where he thinks the only path now is to basically declare the virus public enemy number in addition msnbc contributor karine jean pierre said the xenophobia and racism in the outbreak is such a common thing it is incredibly dangerous it is problematic and it is scary i just want to call that out abc reporter cecilia vega asked the president why do you keep calling this the chinese virus why do you keep using this a lot of people think its racist president trump replied it s not racist at all comes from china that s why media outlets are relatively easy to corrupt given the low level of sophistication of the people who work there the chinese government had bolder aims the chinese instructed their employees and assets in the united states to exert influence on elected officials for example according to an informed yous government official beijing has instructed diplomats in their consulate in san francisco to work with american state and local officials and members of congress to push back against blaming china for this apparently it has worked here s sen chris murphy dconn on cnn earlier this week the reason that we re in the crisis that we are today is not because of anything that china did it s not because of anything the who did it s because of what this president trump did other members of congress voiced similar views often in eerily similar language barbara lee dcalif long this to president trump diseases don t have nationalities china isn t to blame for you fumbling this crisis on march rep judy chu dcalif wrote china did nt unleash anything a virus spread as viruses do blaming china and insisting on calling this the wuhan virus even though every medical expert said not to is putting people s lives in danger stop politicizing this and put people first opinion newsletter just the week before chu wrote that on march a man called zhang ping who runs the chinese consulate in los angeles met with los angeles mayor eric garcetti about the american response to coronavirus he tweeted about it that day look forward to working closely with the city of los angeles to address this common public health challenge and develop closer ties between our cities and peoples we have no idea what ping and garcetti talked about in that meeting we reached out to a number of california lawmakers with a history of closeness to china including senior sen diane feinstein to see if they ve spoken to chinese officials recently none of them responded to our calls and it s not just happening in california according to a story in national review the head of the state senate in wisconsin recently received multiple emails from the wife of the chinese consulategeneral in chicago she asked him to propose a resolution praising china for click here to get the fox news app the entire story of how the government of china has successfully shaped our understanding of the wuhan virus as well as our response to it may take years to tell it may never be fully told at all although we promise to do our best on this show but it s clear how china sees this pandemic not simply or even primarily as a public health disaster in which thousands are dying but as control of the world most americans don t perceive that or understand the profound gravity of the stakes involved how could they our leaders have lied to us about it for years adapted from tucker carlson s monologue from tucker carlson tonight on april click here for more from tucker carlson</s><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad>'"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer.decode(train_data[10]['input_ids'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f7e4c633",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
